{"class":"org.apache.spark.ml.feature.Tokenizer","timestamp":1472758288199,"sparkVersion":"1.6.0","uid":"Tokenizer_432ea9b958e1d5549d32","paramMap":{"outputCol":"words","inputCol":"text"}}
